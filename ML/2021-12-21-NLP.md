---
layout: post
category: languages
title: Natural Language Processing
tags: [NLP, ML]
---

<style>
  body{counter-reset: section 0}
  div.post-body h1:before{
    counter-increment: section;
    content: counter(section) ". ";
  }
</style>

# Natural Language Processing with Classification and Vector Spaces

### Week1: Sentiment Analysis with Logistic Regression

- Logistic Regression 적용해보기
  - tweet의 postiive, negative 판단하기
  - supervised model
- Bag of word, Document-Term Matrix
  - Sparse representation이 문제
  - 중요 단어, 순서, 관계 표현 못함
- 빈도수 합으로 표현
  - corpus내 모든 단어의 PosFreq, NegFreq 구함
  - sumPosFreq: 문장 내 단어들의 PosFreq 합
  - $X_m = [1, \sum_w PosFreq(w), \sum_w NegFreq(w)]$
- preprocessing
  - stopword: and, is, a, at 등 지우기
  - punctuation: 쉼표, 마침표 등 지우기
  - stemming: tune, tuned, tuning
  - lowercasing: 소문자로 바꾸기
- logistic regression
  - classify/predict: $h = sigmoid(\theta \cdot x)$
  - cost function: $J = \frac{-1}{m}(y^T \cdot \log{h} + (1-y)^T \cdot \log(1-h))$
  - update grad: $\theta = \theta - \frac{\alpha}{m} x^T \cdot (h-y)$
  - until cost is low enough

```py
import nltk                                # Python library for NLP
from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK
from nltk.corpus import stopwords          # module for stop words that come with NLTK
from nltk.stem import PorterStemmer        # module for stemming
from nltk.tokenize import TweetTokenizer   # module for tokenizing strings

tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)
stemmer = PorterStemmer() 

def process_tweet(tweet):
  tweet = re.sub(r'^RT[\s]+', '', tweet)
  tweet = re.sub(r'https?://[^\s\n\r]+', '', tweet)
  tweet = re.sub(r'#', '', tweet)
  tokens = tokenizer.tokenize(tweet)
  tokens = [t for t in tokens if not t in stopwords.words('english')]
  tokens = [t for t in tokens if not t in string.punctuation]
  tokens = [stemmer.stem(t) for t in tokens]
  return tokens

def gradientDescent(x, y, theta, alpha, num_iters):
    m = x.shape[0]
    for i in range(0, num_iters):
        z = np.dot(x, theta)
        h = sigmoid(z)
        J = (-1/m) *  (np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h)))
        theta -= (alpha / m) * np.dot(x.T, h - y)
    return float(J), theta
```

### Week2: Sentiment Analysis with Naïve Bayes

### Week3: Vector Space Models

### Week4: Machine Translation and Document Search
